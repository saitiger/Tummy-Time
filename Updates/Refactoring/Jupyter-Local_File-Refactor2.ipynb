{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015965d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "csv.field_size_limit(int(1e9)) \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d0515",
   "metadata": {
    "tags": [
     "read-only"
    ]
   },
   "outputs": [],
   "source": [
    "def processed_file_analysis(filename):\n",
    "    df = pd.read_csv(filename + '_processed_sheet' + '.csv')\n",
    "    df.rename(columns={'A': 'Timing'}, inplace=True)\n",
    "    df['Timing'] = pd.to_datetime(df['Timing'], format='%Y-%m-%d %H:%M:%S:%f')\n",
    "    df['Milliseconds'] = df['Timing'].dt.microsecond // 1000\n",
    "    df['Time Diff'] = df['Milliseconds'].diff().fillna(10.0)\n",
    "    df.loc[df['Time Diff'] < 0, 'Time Diff'] = 10.0\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_row(row, S5=0):\n",
    "    try:\n",
    "        # Read the first column and convert the next three elements to float\n",
    "        A = row[0]\n",
    "        B, C, D = map(float, row[1:4])\n",
    "    except ValueError as e:\n",
    "#         print(f\"Non-numeric data: {row[:4]}\")  # Print the first four elements for context\n",
    "        return None\n",
    "\n",
    "    # Skip rows where B, C, and D are all zero\n",
    "    if B == 0 and C == 0 and D == 0:\n",
    "        return None\n",
    "    \n",
    "    angle_360 = np.sign(B) * np.arccos(-D / np.sqrt(B**2 + D**2)) * 180 / np.pi + 180\n",
    "    angle_updown = np.arcsin(C / np.sqrt(B**2 + C**2 + D**2)) * 180 / np.pi\n",
    "    body_rotation = \"supine-recline\" if S5 < angle_360 < (S5 + 180) else \"prone-sit\"\n",
    "    \n",
    "    if body_rotation == \"prone-sit\":\n",
    "        if angle_updown > 0:\n",
    "            prone_sit_class = \"prone\"\n",
    "        elif angle_updown > -23:\n",
    "            prone_sit_class = \"prone supported\"\n",
    "        elif angle_updown > -63:\n",
    "            prone_sit_class = \"upright\"\n",
    "        else:\n",
    "            prone_sit_class = \"sitting\"\n",
    "        supine_recline_class = \"\"\n",
    "    else:\n",
    "        if angle_updown > 15:\n",
    "            supine_recline_class = \"upsidedown\"\n",
    "        elif angle_updown < -36:\n",
    "            supine_recline_class = \"reclined\"\n",
    "        elif angle_360 < (S5 + 69):\n",
    "            supine_recline_class = \"left side\"\n",
    "        elif angle_360 > (S5 + 101):\n",
    "            supine_recline_class = \"right side\"\n",
    "        else:\n",
    "            supine_recline_class = \"supine\"\n",
    "        prone_sit_class = \"\"\n",
    "    \n",
    "    overall_class = prone_sit_class + supine_recline_class\n",
    "    \n",
    "    return [A, B, C, D, angle_360, angle_updown, body_rotation, prone_sit_class, supine_recline_class, overall_class]\n",
    "\n",
    "def process_dataset(file):\n",
    "    \"\"\"\n",
    "    Process a large dataset from a CSV file.\n",
    "    \n",
    "    :param file: Name of the CSV file (without .csv extension)\n",
    "    \"\"\"\n",
    "    output_file = file.rsplit('.', 1)[0] + '_processed_sheet.csv'\n",
    "    \n",
    "    file = file + '.csv'\n",
    "#     total_rows = 0\n",
    "#     processed_rows = 0\n",
    "#     empty_rows = 0\n",
    "#     invalid_rows = 0\n",
    "    \n",
    "    with open(file, 'rb') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        # Read the file in binary mode\n",
    "        content = infile.read()\n",
    "        \n",
    "        # Try to decode with utf-8, replacing errors\n",
    "        text_content = content.decode('utf-8', errors='replace')\n",
    "        \n",
    "        # Create a CSV reader from the decoded content\n",
    "        reader = csv.reader(io.StringIO(text_content))\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        # Skip header rows\n",
    "        for _ in range(100):\n",
    "            next(reader, None)\n",
    "        \n",
    "        # Write header\n",
    "        writer.writerow(['A','B','C','D','360 angle','Up/down angle',\n",
    "                         'Body Rotation','Prone-sit class','Supine-recline class','Overall class'])\n",
    "        \n",
    "        process_row_partial = partial(process_row)\n",
    "        for row in reader:\n",
    "#             total_rows += 1\n",
    "#             if not row:  # Check for completely empty rows\n",
    "#                 empty_rows += 1\n",
    "#                 continue\n",
    "            \n",
    "            processed_row = process_row_partial(row)\n",
    "            if processed_row:\n",
    "                writer.writerow(processed_row)\n",
    "#                 processed_rows += 1\n",
    "#             else:\n",
    "#                 invalid_rows += 1\n",
    "    \n",
    "    print(f\"Processing complete. Results saved as {output_file} in the current folder\")\n",
    "#     print(f\"Total rows read: {total_rows}\")\n",
    "#     print(f\"Rows successfully processed: {processed_rows}\")\n",
    "#     print(f\"Empty rows skipped: {empty_rows}\")\n",
    "#     print(f\"Invalid rows skipped: {invalid_rows}\")\n",
    "\n",
    "def dataset_description(df):\n",
    "    \n",
    "    class_counts = df['Overall class'].fillna('NaN').groupby(df['Overall class'].fillna('Missing Rows')).count().reset_index(name='Class Count')\n",
    "    class_counts['Duration in seconds'] = class_counts['Class Count'] / 100\n",
    "    class_counts = class_counts[['Overall class', 'Duration in seconds']]\n",
    "    \n",
    "    total_duration_seconds = class_counts['Duration in seconds'].sum()\n",
    "\n",
    "    if total_duration_seconds >= 60:\n",
    "        total_duration_minutes = total_duration_seconds / 60\n",
    "        print(f\"Duration of Video in Minutes: {total_duration_minutes:.2f}\")\n",
    "    else:\n",
    "        print(f\"Duration of Video in Seconds: {total_duration_seconds:.2f}\")\n",
    "    \n",
    "    # statistics = df.describe()\n",
    "    return class_counts, total_duration\n",
    "\n",
    "def create_plot(df):\n",
    "    class_counts = df['Overall class'].fillna('NaN').groupby(df['Overall class'].fillna('Missing Rows')).count().reset_index(name='Class Count')\n",
    "    class_counts['Duration in seconds'] = class_counts['Class Count'] / 100\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Create figure and axes objects\n",
    "    bars = ax.bar(class_counts['Overall class'], class_counts['Duration in seconds'])\n",
    "    \n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval + 1, round(yval, 2), ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_xticklabels(class_counts['Overall class'], rotation=45)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Category')\n",
    "    ax.set_ylabel('Duration in Seconds')\n",
    "    sns.despine(ax=ax, bottom=True, left=True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # st.pyplot(fig)  # Provide the figure to st.pyplot\n",
    "\n",
    "def plot_bins(df, class_name):\n",
    "    same_class_mask = df['Overall class'] == df['Overall class'].shift(1)\n",
    "    df['Increment'] = np.where(same_class_mask, 10, 0)\n",
    "    df['Rolling Sum'] = df['Increment'].groupby((~same_class_mask).cumsum()).cumsum() / 1000\n",
    "    df.drop(columns=['Increment'], inplace=True)\n",
    "    \n",
    "    d = df[df['Overall class'] == class_name].copy()\n",
    "    \n",
    "    # If there are no rows for the given class\n",
    "    if d.empty:\n",
    "        return(f\"No values for class '{class_name}' exist.\")\n",
    "#         st.warning(f\"No values for class '{class_name}' exist.\")\n",
    "#         return\n",
    "    \n",
    "    max_val = d['Rolling Sum'].max()\n",
    "    \n",
    "    fixed_bins = [0.1, 0.2, 0.3, 0.4, 0.5, 1]\n",
    "    variable_bins = np.linspace(1.5, max(max_val, 1.5), num=5)\n",
    "    bins = np.unique(np.sort(np.concatenate((fixed_bins, variable_bins))))\n",
    "    \n",
    "    d['duration_bin'] = pd.cut(d['Rolling Sum'], bins, include_lowest=True)\n",
    "    \n",
    "    cnt_bin = d.groupby(['Overall class', 'duration_bin']).size().reset_index(name='bin_count')\n",
    "    \n",
    "    # Check if all bin counts are zero\n",
    "    if cnt_bin['bin_count'].sum() == 0:\n",
    "        st.warning(f\"No values for class '{class_name}' exist.\")\n",
    "        return\n",
    "    \n",
    "    cnt_bin['duration_bin'] = cnt_bin['duration_bin'].astype(str)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.bar(x='duration_bin', height='bin_count', data=cnt_bin)\n",
    "    \n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval + 1, round(yval, 2), ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_title(f\"Buckets for: {class_name}\")\n",
    "    ax.set_xticklabels(cnt_bin['duration_bin'], rotation=45, ha='right')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Duration (seconds)')\n",
    "    ax.set_ylabel('Count')\n",
    "    sns.despine(ax=ax, bottom=True, left=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    # st.pyplot(fig)\n",
    "    \n",
    "def overall_class_stats(df, overall_class):\n",
    "    class_indices = df[df['Overall class'] == overall_class].index\n",
    "    cnt_arr = []\n",
    "    cnt = max_cnt = 1\n",
    "    start = end = class_indices[0]\n",
    "    \n",
    "    for i in range(len(class_indices) - 1):\n",
    "        if class_indices[i + 1] == class_indices[i] + 1:\n",
    "            cnt += 1\n",
    "            max_cnt = max(cnt, max_cnt)\n",
    "        else:\n",
    "            end = class_indices[i]\n",
    "            cnt_arr.append((cnt, start, end))\n",
    "            start = class_indices[i + 1]\n",
    "            cnt = 1\n",
    "    \n",
    "    cnt_arr.append((cnt, start, end))  # To account for the last sequence\n",
    "    max_sequence = max(cnt_arr, key=lambda x: x[0])\n",
    "    \n",
    "    return max_sequence\n",
    "\n",
    "def display_dataset(df):\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f256819-1735-4fd2-994d-f984e72a1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = input(\"Enter folder path : \")\n",
    "os.chdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8e736",
   "metadata": {},
   "source": [
    "# Enter File Name Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395219e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = input(\"Enter file name : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f89acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processed_file_analysis(file_name)\n",
    "display_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2da26",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18465624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_description(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = input(\"Enter Class name : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_class_stats(df,class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e21cf",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad699e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_name = input(\"Enter Class name : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bins(df,position_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
